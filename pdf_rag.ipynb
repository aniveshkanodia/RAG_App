{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d54f18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akanodia/opt/anaconda3/envs/rag_app/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ade1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    #Load the PDF Document\n",
    "    loader = PyPDFLoader(\"documents/AI in 2024.pdf\")\n",
    "    pages = loader.load_and_split()\n",
    "    '''\n",
    "    loader.load will load the entire pdf in 1 document object.\n",
    "    load_and_split create separate document object for every split.\n",
    "    '''\n",
    "    #split pages by char\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 100,\n",
    "        length_function = len,\n",
    "        add_start_index = True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    print(f\"Split {len(pages)} documents into {len(chunks)} chunks.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3bfdbbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 15 documents into 38 chunks.\n"
     ]
    }
   ],
   "source": [
    "document_chunks = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b361e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise the models \n",
    "\n",
    "#ollama pull qwen3-embeddings\n",
    "embeddings = OllamaEmbeddings(model=\"qwen3-embedding:0.6b\")\n",
    "\n",
    "#Initialise vector store\n",
    "vectordb = Chroma(collection_name=\"documents\", embedding_function = embeddings, persist_directory=\"./db/chroma_db\") #path to save data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc31a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "516cb08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab44886a-9128-42d0-91d0-06aee60d07e9', '752cec16-69c1-4ce9-9298-7132a2b4abc9', '9fc4854f-f14d-454b-8b3f-557338c4d76e']\n"
     ]
    }
   ],
   "source": [
    "#store documents in vectordb\n",
    "document_ids = vectordb.add_documents(documents=document_chunks)\n",
    "print(document_ids[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4a8ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the retrieval chain\n",
    "retriever = vectordb.as_retriever(search_type = \"similarity\",\n",
    "                                  search_kwargs={\n",
    "                                        \"k\":4\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2410b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama pull qwen3\n",
    "llm = ChatOllama(model=\"qwen3:0.6b\",keep_alive=\"2h\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fa50b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the chat prompt\n",
    "chat_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Use the context to answer the question. If you don’t know, say you don’t know.\"),\n",
    "        (\"human\", \"{context}\\n\\nQuestion: {question}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b356cdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve context\n",
    "\n",
    "retrieve_context = RunnableLambda(\n",
    "    lambda input_dict: {\n",
    "        \"context\": \"\\n\\n\".join(\n",
    "            doc.page_content for doc in retriever.invoke(input_dict[\"question\"])\n",
    "        ),\n",
    "        \"question\": input_dict[\"question\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fccaf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = retrieve_context | chat_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f36a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"The key trends in AI for 2024, as highlighted in the context, include topics such as **Dataiku's advancements in AI integration**, **Deloitte's focus on business transformation through AI**, and **Snowflake's role in data analytics**. These trends are part of the 2024 hot takes from the specified companies, which are already covered in the provided information.\" additional_kwargs={} response_metadata={'model': 'qwen3:0.6b', 'created_at': '2025-10-28T14:22:16.891843Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10785232083, 'load_duration': 6423877375, 'prompt_eval_count': 227, 'prompt_eval_duration': 535375041, 'eval_count': 455, 'eval_duration': 3649295927, 'model_name': 'qwen3:0.6b', 'model_provider': 'ollama'} id='lc_run--c0de88e2-b5df-490c-ad4d-a9de87f57a0a-0' usage_metadata={'input_tokens': 227, 'output_tokens': 455, 'total_tokens': 682}\n"
     ]
    }
   ],
   "source": [
    "#Execute the pipeline\n",
    "input_data = {\n",
    "    \"question\": \"What are the key trends in AI for 2024?\"}\n",
    "result = pipeline.invoke(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35a82643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output parser to pipeline to extract answer only\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd2d19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_parser = pipeline | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f75da01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The challenges related to AI adoption include:  \n",
      "1. **Accepting AI's limitations** to avoid unintended consequences and plan responsibly.  \n",
      "2. **Balancing innovation with forward-thinking** to manage control mechanisms and technological guardrails.  \n",
      "3. **Addressing trust erosion** by redefining accountability and responsibilities across the organization.  \n",
      "4. **Ensuring transparent and open communication** with stakeholders, beyond just regulatory compliance, to maintain trust and collaboration.\n"
     ]
    }
   ],
   "source": [
    "#Execute the pipeline with output parser\n",
    "input_data = {\n",
    "    \"question\": \"What challenges exist regarding AI adoption?\"}\n",
    "result = pipeline_with_parser.invoke(input_data)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
